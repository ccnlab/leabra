\section{Appendix: Implementational Details}

The model was implemented using the Leabra framework, which is described in detail in \incite{OReillyMunakataFrankEtAl12}, \incite{OReillyMunakata00}, \incite{OReilly01}, and summarized here.  See Table~\ref{tab.sim_params} for a listing of parameter values, nearly all of which are at their default settings.  These same parameters and equations have been used to simulate over 40 different models in \incite{OReillyMunakataFrankEtAl12} and \incite{OReillyMunakata00}, and a number of other research models.  Thus, the model can be viewed as an instantiation of a systematic modeling framework using standardized mechanisms, instead of constructing new mechanisms for each model.  The model can be obtained by emailing the first author at randy.oreilly@colorado.edu.

\subsection{Pseudocode}

The pseudocode for Leabra is given here, showing exactly how the
pieces of the algorithm described in more detail in the subsequent
sections fit together.

Outer loop: Iterate over events (trials) within an epoch.  For each event:
\begin{enumerate}
\item Iterate over minus and plus phases of settling for each event.
  \begin{enumerate}
  \item At start of settling, for all units:
    \begin{enumerate}
    \item Initialize all state variables (activation, v\_m, etc).
    \item Apply external patterns (clamp input in minus, input \&
      output in plus).
    \end{enumerate}
  \item During each cycle of settling, for all non-clamped units:
    \begin{enumerate}
    \item Compute excitatory netinput ($g_e(t)$ or $\eta_j$,
      eq~\ref{eq.net_in_avg}).
    \item Compute kWTA inhibition for each layer, based on $g_i^{\Theta}$
      (eq~\ref{eq.i_at_thr}):
      \begin{enumerate}
      \item Sort units into two groups based on $g_i^{\Theta}$: top $k$ and
        remaining $k+1$ to $n$.
      \item If basic, find $k$ and $k+1th$ highest; if
        avg-based, compute avg of $1\rightarrow k$ \& $k+1
        \rightarrow n$.
      \item Set inhibitory conductance $g_i$ from $g^{\Theta}_k$ and
        $g^{\Theta}_{k+1}$ (eq~\ref{eq.g_i}).
      \end{enumerate}
    \item Compute point-neuron activation combining excitatory input and
      inhibition (eq~\ref{eq.vm}).
    \end{enumerate}
  \item After settling, for all units:
    \begin{enumerate}
    \item Record final settling activations as either minus or plus
      phase ($y^-_j$ or $y^+_j$).
    \end{enumerate}
  \end{enumerate}
  \item After both phases update the weights (based on linear current
    weight values), for all connections:
  \begin{enumerate}
  \item Compute error-driven weight changes (eq~\ref{eq.err}) with
    soft weight bounding (eq~\ref{eq.err_soft_bound}).
  \item Compute Hebbian weight changes from plus-phase activations
    (eq~\ref{eq.hebb}).
  \item Compute net weight change as weighted sum of error-driven and
    Hebbian (eq~\ref{eq.k_hebb}).
  \item Increment the weights according to net weight change.
  \end{enumerate}
\end{enumerate}

\subsection{Point Neuron Activation Function} 

\begin{table}
  \centering
  \begin{tabular}{ll|ll} \hline
Parameter & Value & Parameter & Value \\ \hline
$E_l$ & 0.15 & $\overline{g_l}$ & 0.10 \\
$E_i$ & 0.15 & $\overline{g_i}$ & 1.0 \\
$E_e$ & 1.00 & $\overline{g_e}$ & 1.0 \\
$V_{rest}$ & 0.15 & $\Theta$    & 0.25 \\
$\tau$ & .02 & $\gamma$ & 600 \\
$k$ Post Ctx & 2* & $k$ Output  & 1* \\
$k$ Feat PFC & 2* & $k$ Dim PFC & 1* \\
$k_{hebb}$ & .02 & $\epsilon$ & .01 \\
to AC $\epsilon$ & .04* & \\ \hline
  \end{tabular}
  \caption{\small Parameters for the simulation (see equations in text
    for explanations of parameters).  All are standard
    default parameter values except for those with a * (most of which
    have no default because they are intrinsically task-dependent).
    The faster learning rate ($\epsilon$) for connections into the AC
    was important for ensuring rapid learning of reward.}
  \label{tab.sim_params}
\end{table}

Leabra uses a {\em point neuron} activation function that models the electrophysiological properties of real neurons, while simplifying their geometry to a single point.  This function is nearly as simple computationally as the standard sigmoidal activation function, but the more biologically-based implementation makes it considerably easier to model inhibitory competition, as described below.  Further, using this function enables cognitive models to be more easily related to more physiologically detailed simulations, thereby facilitating bridge-building between biology and cognition.

The membrane potential $V_m$ is updated as a function of ionic conductances $g$ with reversal (driving) potentials $E$ as follows:
\begin{equation}
  \Delta V_m(t) = \tau \sum_c g_c(t) \overline{g_c} (E_c - V_m(t))
  \label{eq.vm}
\end{equation}
with 3 channels ($c$) corresponding to: $e$ excitatory input; $l$ leak current; and $i$ inhibitory input.  Following electrophysiological convention, the overall conductance is decomposed into a time-varying component $g_c(t)$ computed as a function of the dynamic state of the network, and a constant $\overline{g_c}$ that controls the relative influence of the different conductances.  The equilibrium potential can be written in a simplified form by setting the excitatory driving potential ($E_e$) to 1 and the leak and inhibitory driving potentials ($E_l$ and $E_i$) of 0:
\begin{equation}
  V_m^\infty = \frac{g_e \overline{g_e}} {g_e
   \overline{g_e} + g_l \overline{g_l} + g_i \overline{g_i}}  
\end{equation}
which shows that the neuron is computing a balance between excitation and the opposing forces of leak and inhibition.  This equilibrium form of the equation can be understood in terms of a Bayesian decision making framework \cite{OReillyMunakata00}.

The excitatory net input/conductance $g_e(t)$ or $\eta_j$ is computed as the proportion of open excitatory channels as a function of sending activations times the weight values:
\begin{equation}
  \eta_j = g_e(t) = \langle x_i \wij \rangle = \oneo{n} \sum_i x_i \wij
  \label{eq.net_in_avg}
\end{equation}
The inhibitory conductance is computed via the kWTA function described in the next section, and leak is a constant.

Activation communicated to other cells ($y_j$) is a thresholded ($\Theta$) sigmoidal function of the membrane potential with gain parameter $\gamma$:
\begin{equation}
  y_j(t) = \oneo{\left(1 + \oneo{\gamma [V_m(t) - \Theta]_+} \right)}
\end{equation}
where $[x]_+$ is a threshold function that returns 0 if $x<0$ and $x$ if $X>0$.  Note that if it returns 0, we assume $y_j(t) = 0$, to avoid dividing by 0.  As it is, this function has a very sharp threshold, which interferes with graded learning learning mechanisms (e.g., gradient descent).  To produce a less discontinuous deterministic function with a softer threshold, the function is convolved with a Gaussian noise kernel ($\mu=0$, $\sigma=.005$), which reflects the intrinsic processing noise of biological neurons:
\begin{equation}
  y^*_j(x) = \int_{-\infty}^{\infty} \oneo{\sqrt{2 \pi} \sigma}
  e^{-z^2/(2 \sigma^2)} y_j(z-x) dz
  \label{eq.conv}
\end{equation}
where $x$ represents the $[V_m(t) - \Theta]_+$ value, and $y^*_j(x)$ is the noise-convolved activation for that value.  In the simulation, this function is implemented using a numerical lookup table.

\subsection{k-Winners-Take-All Inhibition}

Leabra uses a kWTA (k-Winners-Take-All) function to achieve inhibitory competition among units within a layer (area).  The kWTA function computes a uniform level of inhibitory current for all units in the layer, such that the $k+1$th most excited unit within a layer is generally below its firing threshold, while the $k$th is typically above threshold.  Activation dynamics similar to those produced by the kWTA function have been shown to result from simulated inhibitory interneurons that project both feedforward and feedback inhibition \cite{OReillyMunakata00}.  Thus, although the kWTA function is somewhat biologically implausible in its implementation (e.g., requiring global information about activation states and using sorting mechanisms), it provides a computationally effective approximation to biologically plausible inhibitory dynamics.

kWTA is computed via a uniform level of inhibitory current for all units in the layer as follows:
\begin{equation}
  g_i = g^{\Theta}_{k+1} + q (g^{\Theta}_k - g^{\Theta}_{k+1})
  \label{eq.g_i}
\end{equation}
where $0<q<1$ (.25 default used here) is a parameter for setting the inhibition between the upper bound of $g^{\Theta}_k$ and the lower bound of $g^{\Theta}_{k+1}$.  These boundary inhibition values are computed as a function of the level of inhibition necessary to keep a
unit right at threshold:
\begin{equation}
  g_i^{\Theta} = \frac{g^*_e \bar{g_e} (E_e - \Theta) +
    g_l \bar{g_l} (E_l - \Theta)}{\Theta - E_i}
  \label{eq.i_at_thr}
\end{equation}
where $g^*_e$ is the excitatory net input without the bias weight contribution --- this allows the bias weights to override the kWTA constraint.

In the basic version of the kWTA function, which is relatively rigid about the kWTA constraint and is therefore used for output layers, $g^{\Theta}_k$ and $g^{\Theta}_{k+1}$ are set to the threshold inhibition value for the $k$th and $k+1$th most excited units, respectively.  Thus, the inhibition is placed exactly to allow $k$ units to be above threshold, and the remainder below threshold.  For this version, the $q$ parameter is almost always .25, allowing the $k$th unit to be sufficiently above the inhibitory threshold.

In the {\em average-based} kWTA version, $g^{\Theta}_k$ is the average $g_i^{\Theta}$ value for the top $k$ most excited units, and $g^{\Theta}_{k+1}$ is the average of $g_i^{\Theta}$ for the remaining $n-k$ units.  This version allows for more flexibility in the actual number of units active depending on the nature of the activation distribution in the layer and the value of the $q$ parameter (which is typically .6), and is therefore used for hidden layers.

\subsection{Hebbian and Error-Driven Learning} 

For learning, Leabra uses a combination of error-driven and Hebbian learning.  The error-driven component is the symmetric midpoint version of the GeneRec algorithm \cite{OReilly96}, which is functionally equivalent to the deterministic Boltzmann machine and contrastive Hebbian learning (CHL).  The network settles in two phases, an expectation (minus) phase where the network's actual output is produced, and an outcome (plus) phase where the target output is experienced, and then computes a simple difference of a pre and
postsynaptic activation product across these two phases.  For Hebbian learning, Leabra uses essentially the same learning rule used in competitive learning or mixtures-of-Gaussians which can be seen as a variant of the Oja normalization \cite{Oja82}.  The error-driven and Hebbian learning components are combined additively at each connection to produce a net weight change.

The equation for the Hebbian weight change is:
\begin{equation}
  \Delta_{hebb} \wij = x^+_i y^+_j - y^+_j \wij = y^+_j (x^+_i - \wij)
  \label{eq.hebb}
\end{equation}
and for error-driven learning using CHL:
\begin{equation}
  \Delta_{err} \wij = (x^+_i y^+_j) - (x^-_i y^-_j)
  \label{eq.err}
\end{equation}
which is subject to a soft-weight bounding to keep within the $0-1$ range:
\begin{equation}
  \Delta_{sberr} \wij = [\Delta_{err}]_+ (1-\wij) + [\Delta_{err}]_- \wij
  \label{eq.err_soft_bound}
\end{equation}
The two terms are then combined additively with a normalized mixing constant $k_{hebb}$:
\begin{equation}
  \Delta \wij = \epsilon[k_{hebb} (\Delta_{hebb}) + (1-k_{hebb}) (\Delta_{sberr})]
  \label{eq.k_hebb}
\end{equation}

\subsection{Weight Contrast Enhancement} 

One limitation of the Hebbian learning algorithm is that the weights linearly reflect the strength of the conditional probability.  This linearity can limit the network's ability to focus on only the strongest correlations, while ignoring weaker ones.  To remedy this limitation, we introduce a contrast enhancement function that magnifies the stronger weights and shrinks the smaller ones in a parametric, continuous fashion.  This contrast enhancement is achieved by passing the linear weight values computed by the learning rule
through a sigmoidal nonlinearity of the following form:
\begin{equation}
  \hat{w}_{ij} = \oneo{1 + \left(\frac{\wij}{\theta (1-\wij)}\right)^{-\gamma}}
  \label{eq.wt_off}
\end{equation}
where $\hat{w}_{ij}$ is the contrast-enhanced weight value, and the sigmoidal function is parameterized by an offset $\theta$ and a gain $\gamma$ (standard defaults of 1.25 and 6, respectively, used here).  


\subsection{Temporal Differences and Adaptive Critic Gating Mechanisms} 

To implement the temporal-differences (TD) algorithm in Leabra, the adaptive critic (AC) unit in the VTA layer has plus-minus phase states that correspond to the expected reward at the previous time step (minus) and the current time step (plus).  The difference between these two states is the TD error $\delta$, which is essentially equivalent to the more standard kinds of error signals computed by the error-driven learning component of Leabra, except that it represents an error of prediction over time, instead of an instantaneous error in the network output.

The AC--PFC relationship is formalized in the model with the following equations for the gating (multiplicative scaling) terms $s_{in}$ (the weight scaling of the PFC inputs) and $s_{maint}$ (the weight-scaling of the PFC self-maintenance connections):
\begin{eqnarray}
  s_{in} = b_{in} + \delta + \nu\\
  s_{maint} = b_{maint} + \delta + \nu
  \label{eq.pfc_gain_mod}
\end{eqnarray}
where $\delta$ is the change in AC activation (TD error), and $\nu$ is a Gaussian random noise value that allows for random trial-and-error exploration ($\mu=0$, $\sigma=.2$).  The base-level parameters $b_{in}$ and $b_{maint}$ determine the basic level of each weight-scaling (gain) parameter, and are set to 0 and 1, respectively.  Both of the weight-scaling terms are bounded between 0 and 1.  These differences in input and maintenance connections could result from different dopamine receptor affinities, and have the effect that the inputs tend to weakly impact the PFC units except during a positive $\delta$, while the maintenance connections are relatively strong except during a negative
$\delta$.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
