%% PNAStwoS.tex
%% Sample file to use for PNAS articles prepared in LaTeX
%% For two column PNAS articles
%% Version1: Apr 15, 2008
%% Version2: Oct 04, 2013

%% BASIC CLASS FILE
\documentclass{pnastwo}

%% author YS: allow including figures in pdf version 1.6 without warning
\pdfoptionpdfminorversion 6


%% ADDITIONAL OPTIONAL STYLE FILES Font specification

%\usepackage{pnastwoF}
\usepackage{amssymb,amsfonts,amsmath}


%% OPTIONAL MACRO DEFINITIONS
%\def\s{\sigma}
%%%%%%%%%%%%
%% For PNAS Only:
%\url{www.pnas.org/cgi/doi/10.1073/pnas.0709640104}
%\copyrightyear{2008}
%\issuedate{Issue Date}
%\volume{Volume}
%\issuenumber{Issue Number}
%%\setcounter{page}{2687} %Set page number here if desired
%%%%%%%%%%%%

\begin{document}

\title{Latent structure in random sequences drives neural learning toward a rational bias}

\author{Yanlong Sun\affil{1}{Center for Biomedical Informatics, Texas A\&M University Health Science Center},
Randall C. O'Reilly\affil{2}{Department of Psychology and Neuroscience, University of Colorado Boulder},
Rajan Bhattacharyya\affil{3}{Center for Neural and Emergent Systems, HRL Laboratories, LLC},
Jack W. Smith\affil{1}{},
Xun Liu\affil{4}{Institute of Psychology, Chinese Academy of Sciences},
\and
Hongbin Wang\affil{1}{}}

\contributor{Submitted to Proceedings of the National Academy of Sciences
of the United States of America}


\significancetext{The human mind has a unique capacity to find order in chaos.
The way the neocortex integrates information over time enables the mind to capture rich statistical structures embedded in random sequences.
We show that a biologically-motivated neural network model reacts to not only how often a pattern occurs (mean time) but also when a pattern is first encountered (waiting time).
This behavior naturally produces the alternation bias in the gambler's fallacy,
and provides a neural grounding for the Bayesian models of human behavior in randomness judgments.
Our findings support a rational account for human probabilistic reasoning, and a unifying perspective that connects the implicit learning without instruction with the generalization under structured and expressive rules.}%% word count: 118 (max: 120)

\maketitle

\begin{article}
\begin{abstract}
  People generally fail to produce random sequences by overusing alternating patterns and avoiding repeating ones --- the gambler's fallacy bias.
  We offer a novel account for the neural basis of this bias, based on a biologically-motivated neural model that learns from errors in predicting what will happen next.
  Through mere exposure to random sequences over time, the model naturally develops a representation that is biased toward alternation, because of its sensitivity to some surprisingly rich statistical structure that emerges in these random sequences.
  Furthermore, the model directly produces the best-fitting bias-gain parameter for an existing Bayesian model, by which we obtain an accurate fit to the human data in random sequence production.
  These results show that our seemingly irrational, biased view of randomness can be understood instead as the perfectly reasonable response of an effective learning mechanism to subtle statistical structure embedded in random sequences.
\end{abstract}%% word count: 148 (max: 250)

\keywords{gambler's fallacy | waiting time | neural network | Bayesian inference}


\dropcap{P}eople are prone to search for patterns in sequences of events, even when the sequences are completely random.
In a famous game of roulette at the Monte Carlo casino in 1913, black repeated a record 26 times---people began extreme betting on red after about 15 repetitions \cite{HuffD1959}.
The gambler's fallacy---a belief that chance is a self-correcting process where a deviation in one direction would induce a deviation in the opposite direction---has been deemed a misperception of random sequences \cite{Tversky1971}.
For decades, this fallacy is thought to have originated from the ``representativeness bias'', in which a sequence of events generated by a random process is expected to represent the essential characteristics of that process even when the sequence is short \cite{Tversky1974}.


However, there is a surprising amount of systematic structure lurking within random sequences.
For example, in the classic case of tossing a fair coin, where the probability of each outcome (Heads or Tails) is exactly $0.5$ on every single trial, one would naturally assume that there is no possibility for some kind of interesting structure to emerge, given such a simple and desolate form of randomness.
And yet, if one records the average amount of time for a pattern to \emph{first occur} in a sequence (i.e., the \emph{waiting time} statistic), it is significantly longer for a repetition (\texttt{HH} or \texttt{TT}, $6$ tosses) than for an alternation (\texttt{HT} or \texttt{TH}, $4$ tosses).
This is despite the fact that on average, repetitions and alternations are equally probable (occurring once in every $4$ tosses, i.e., the same \emph{mean time} statistic).
For both of these facts to be true, it must be that repetitions are more bunched together over time --- they come in bursts, with greater spacing between, compared to alternations.
Intuitively, this difference comes from the fact that repetitions can build upon each other (e.g., sequence \texttt{HHH} contains $2$ instances of \texttt{HH}), whereas alternations cannot.
Statistically, the mean time and waiting time delineate the \emph{mean} and \emph{variance} in the distribution of the inter-arrival times of patterns, respectively \cite{Sun2010jdm}.
In spite of the same frequency of occurrence (i.e., the same mean), alternations are more evenly distributed over time than repetitions (i.e., different variances).
Another source of insight comes from the transition graph (\textbf{Figure~1A}), which reveals a structural asymmetry in the process of fair coin tossing.
For example, when the process has the same chance to visit any of the states, the minimum number of transitions it takes to leave then revisit a repetition state is longer than that for an alternation state.
Let $p_A$ denote the \emph{probability of alternation} between any two consecutive trials, in spite of the same mean time at $p_A = 1/2$,
repetitions will have longer waiting times than alternations as long as $p_A > 1/3$ (\textbf{Figure~1B}).
(See \textbf{Supporting Information} for the calculation of mean time and waiting time statistics.)

%%% insert Figure 1 about here

Is this latent structure of waiting time just a strange mathematical curiosity, or could it possibly have deep implications for our cognitive-level perceptions of randomness?
It has been speculated that the systematic bias in human randomness perception such as the gambler's fallacy might be due to the greater variance in the inter-arrival times or the ``delayed'' waiting time for repetition patterns \cite{Sun2010jdm,Sun2010cogpsy}.
Here, we show that a neural model based on a detailed biological understanding of the way the neocortex integrates information over time when processing sequences of events \cite{OReilly2012wiki,OReilly2014TI}, is naturally sensitive to both the mean time and waiting time statistics.
Indeed, its behavior is explained by a simple averaging of the influences of both of these statistics, and this behavior emerges in the model over a wide range of parameters.
Furthermore, this averaging dynamic directly produces the best-fitting bias-gain parameter for an existing Bayesian model of randomness judgments \cite{Griffiths2001}, which was previously an unexplained free parameter and obtained only through parameter fitting.
We also show that we can extend this Bayesian model to better fit the full range of human data by including a higher-order pattern statistic, and the neurally-derived bias-gain parameter still provides the best fit to the human data in the augmented model.
Overall, our model provides a neural grounding for the pervasive gambler's fallacy bias in human judgments of random processes, where people systematically discount repetitions, and emphasize alternations \cite{Falk1997,Nickerson2002}.



\section{Neural Model of Temporal Integration}
Our neural model is extremely simple (\textbf{Figure~2A}).
It consists of a sensory input layer with distinct non-overlapping patterns for heads (\texttt{H}) versus tails (\texttt{T}),
and an internal prediction layer that attempts to predict the next input, while the prior inputs in the sequence are encoded in the temporal context.
This model is based on a biologically-motivated computational framework that has been used to explain the neural basis of cognition in a wide range of different domains \cite{OReilly2012wiki},
with the benefit of integrating prior temporal context information according to the properties of the deep neocortical neurons (layers $5b$ and $6$) \cite{OReilly2014TI}.

Notably, this neural model is not designed to merely mimic certain types of human behavior by arbitrary parameter fitting.
Instead, based on a set of biologically-plausible parameters that have been tested in a wide variety of tasks \cite{OReilly2012wiki,OReilly2014TI}, we make a strong prediction that the model should be able to naturally capture the waiting time statistics of temporal patterns.
(See \textbf{Supporting Information} for an extensive exploration of model parameters and alternative model inputs, which demonstrates the robustness of our result, and that it depends critically on the learning mechanism of temporal integration and the waiting time statistics.)
Of course, this model will generally fail to accurately predict each single trial in a random sequence, but nevertheless, exercising the model leads to the development of representations that are adapted to the systematic structure in the learning environment.

%%% insert Figure 2 about here

The model was trained with binary sequences generated at various levels of the probability of alternation ($p_A$),
each sequence consisting of $10,\!000$ coin tosses (although learning occurred quickly within a few hundred trials).
Crucially, learning concerned only reconstructing the input sequence and not pattern discrimination, as no teaching signals were provided regarding the underlying $p_A$ values and pattern time statistics.
After training, the model was tested with a sequence of $1,\!000$ tosses generated at the same $p_A$ level as in the training sequence.
We then decoded these sequence representations through a reverse correlation technique.
Based on the sensitivity of the unit activations to the temporal patterns of length $2$, we classified then counted the number of the units on the internal prediction layer as either Repetition detectors ($R$, being sensitive to either \texttt{HH} or \texttt{TT}) or Alternation detectors ($A$, being sensitive to either \texttt{HT} or \texttt{TH}).
(See \textbf{Supporting Information} for the method of detector classification.)

Most intriguingly, at $p_A=1/2$ (i.e., independent tosses of a fair coin), the model produced a ratio of $R/A \approx 0.70$ --- in spite of the equal frequency of pattern occurrences, repetition detectors were significantly less likely than alternation detectors.
Such alternation bias is in the same direction of the representativeness bias, where people perceive alternation patterns as more representative of a random process than repetition patterns \cite{Tversky1971,Tversky1974}.
Effectively, this result demonstrates the gambler's fallacy emerging naturally as a consequence of the alternation bias, due to the model's sensitivity to the waiting time advantage of alternations compared to repetitions.

We then used the $R/A$ ratio to compute the \emph{subjective probability of alternation}, $p'_A$, as the model's internal representation of its actually experienced $p_A$.
With $R/A \approx 0.70$, we have,
\begin{equation}\label{eq:subjective-pa}
  p'_A = \frac{A}{R+A} = \frac{1}{1+ R/A} \approx 0.59
\end{equation}
This $p'_A$ value is consistent with the empirical findings on subjective randomness.
From a comprehensive review of the studies on random sequence perception and generation, it was found that the subjective probability of alternation was around $0.58\sim0.63$ \cite{Falk1997}.


To further characterize the nature of the alternation bias, we systematically varied the probability of alternation ($p_A$) in generating the training sequence (i.e., departures from tossing a fair coin independently), then, measured the effects on the $R/A$ ratio.
We found a smooth curve, where the $R/A$ ratio increased (more Repetition detectors) as $p_A$ decreased (less frequent occurrences of alternations).
At $p_A = 3/7$, the model reached an equilibrium point with equal numbers of repetition and alternation detectors, $R/A = 1$  (\textbf{Figure~2B}).
That is, alternations have to be this much less frequent (i.e., greater mean time) to cancel out their waiting time advantage.
This corresponds exactly to the equilibrium point where repetitions and alternations have the same sum of mean and waiting times (\textbf{Figure~1B}).



Overall, the model's behavior can be mostly replicated by a simple equation that averages the effects of the mean time and waiting time statistics (the dotted line in \textbf{Figure~2B}):
\begin{equation}\label{eq:time-ratio-squared}
  \frac{R}{A} \approx \left(\frac{E[T_A]+E[T^*_A]}{E[T_R]+E[T^*_R]}\right)^2
\end{equation}
where $E[T]$ is the mean time, $E[T^*]$ is the waiting time, and subscripts $R$ and $A$ represent repetitions and alternations, respectively.
This establishes a clear higher-level explanation for the emergent behavior of the model, allowing us to summarize its behavior as simply averaging the effects of these two relevant statistics over the random sequences.



\section{Bayesian Models of Random Sequence Production}
A unifying perspective on human statistical learning requires bridging the gap between the implicit learning without instruction, and the generalization of the learned patterns under structured and expressive rules \cite{Aslin2012}.
On the one hand, our neural model shows that through mere exposure to a set of input stimuli, a systematic bias was developed towards the alternation pattern in random sequences.
On the other hand, recent Bayesian accounts for probabilistic learning suggest that the human mind performs rational inferences at both neural and behavioral levels \cite{Pouget2013,Tenenbaum2011}.
Then, we asked whether it was possible to relate the emergent behavior of the neural model to an existing Bayesian model of randomness judgments,
specifically, whether we could demonstrate a quantitative connection between the bias for local patterns at the neural level and the behavior of generating longer random sequences governed by the rules of Bayesian inference.

Let $f(H,T)$ denote the degree of the belief that a sequence of coin tosses consisting of $H$ heads and $T$ tails is generated by a fair coin, where the probability of heads in any single toss is $p = 1/2$.
By Bayes' theorem, assuming a uniform prior distribution $p \in [0,1]$, $f(H,T)$ can be formulated as the posterior probability density,
\begin{align}\label{eq:bayesian-fair-coin}
\begin{split}
  f(H,T) &= \frac{2^{-(H+T)}}{\int_0^1 p^H (1-p)^T dp} \\
    &= 2^{-(H+T)} (H+T+1) \binom{H+T}{H}
\end{split}
\end{align}

Because of the binomial coefficient $\binom{H+T}{H}$, Equation~\ref{eq:bayesian-fair-coin} is maximized when $H=T$.
That is, governed by the belief function $f(H,T)$, the optimal solution to generating a random sequence is to always seek for a balance between the numbers of heads and tails \cite{Nickerson2002}.
Based on this belief function, Griffiths and Tenenbaum (2001) proposed a Bayesian model of random sequence production \cite{Griffiths2001}.
They first defined a likelihood function, $L_k$, to represent the local representativeness that choosing a head instead of a tail as the outcome of the $k^{th}$ toss would result in a more random sequence:
\begin{align}\label{eq:log-likelihood-L}
  \begin{split}
  L_k &= \sum_{i=1}^{k-1} \log f(H_i + 1, T_i) - \log f(H_i, T_i + 1) \\
      &= \log \prod_{i=1}^{k-1} \left(\frac{T_i + 1}{H_i + 1} \right), \quad k \geq 2
  \end{split}
\end{align}
where $H_i$ and $T_i$ were, respectively, the numbers of heads and tails counting back $i$ steps in the sequence.
Then, with a free parameter ($\lambda$) to scale the contribution of $L_k$, the probability of choosing a head at each response ($R_k$) was obtained by a logistic function:
\begin{equation}\label{eq:model-GT2001}
    P(R_k = \mathtt{H}) = \frac{1}{1+e^{-\lambda L_k}}
\end{equation}

This Bayesian model was then used to fit a massive database from the ``Zenith radio experiment'', where $20,\!099$ participants attempted to produce $5$ random binary symbols one at a time \cite{Goodfellow1938}.
It was found that a $\lambda$ value of around $0.60$ produced the optimal fit to $15$ out of the $16$ data points from the human data (\textbf{Figure~3A}).

%%% insert Figure 3 about here

The Bayesian model provides a formalization of the representativeness heuristic \cite{Tversky1971,Tversky1974}.
It captures the idea that when generating a random sequence, people are seeking for a balance between heads and tails not only in the global sequence, but also in the local sub-sequences \cite{Nickerson2002}.
Apparently, the extent to which this balance is adjusted is determined by the free scaling parameter $\lambda$ in Equation~\ref{eq:model-GT2001}.
However, beyond parameter fitting, the Bayesian model does not have any independent basis for specifying this parameter.

In the light of the neural model's behavior, we predict that the scaling parameter $\lambda$ should have originated naturally from people's actual experiences of random sequences in the learning environment.
Specifically, we can deduce from Equation~\ref{eq:model-GT2001} that $\lambda$ actually serves as a \emph{bias-gain} parameter that modulates the strength of an alternation bias:
\begin{equation}\label{eq:sub-pa-by-lambda}
  p'_A = P(R_2=\mathtt{T} | R_1=\mathtt{H}) = \frac{1}{1+2^{-\lambda}}
\end{equation}
With $\lambda=0$,  Equation~\ref{eq:sub-pa-by-lambda} produces unbiased responses with the subjective probability of alternation $p'_A = 1/2$, corresponding to the process of independent coin tossing;
And, higher values $\lambda>0$ produce an increasing alternation bias where $p'_A > 1/2$.

Then,  we are able to show that $\lambda$ can actually be derived from the behavior of the neural model.
Substituting $p'_A$ in Equation~\ref{eq:sub-pa-by-lambda} with Equation~\ref{eq:subjective-pa}, $\lambda$ can be computed directly from the $R/A$ ratio:
\begin{equation}\label{eq:lambda-by-RA}
  \lambda = - \log_2(R/A)
\end{equation}
For independent fair coin tossing (i.e., $p_A=1/2$), the neural model showed $R/A \approx 0.7$, resulting in $\lambda \approx 0.51$ ---
precisely the value that optimizes the fit to all $16$ data points from the human data (\textbf{Figures~3A and 3B}).

The implication of Equation~\ref{eq:lambda-by-RA} is that the naturally emergent properties of the neural model can in effect provide an independent anchor to the previously free parameter in the Bayesian model.
Specifically, it shows that the bias-gain parameter $\lambda$ is anchored to the alternation bias, which has been learned by the neural model through mere exposure to random sequences of fair coin tossing.
Moreover, Equation~\ref{eq:lambda-by-RA} is in accord with the subjective probability of alternation $p'_A$ (Equation~\ref{eq:subjective-pa}), and, normatively, the average of the mean and waiting time statistics of local patterns (Equation~\ref{eq:time-ratio-squared}).
Most significantly, the derivation of the $\lambda$ value demonstrates the quantitative connection between the implicit learning without instruction and the generalization of the learned patterns under structured and expressive rules, supporting a unified perspective on these two different learning mechanisms \cite{Aslin2012}.
This represents a remarkable convergence across multiple levels of analysis, and further bolsters the validity of our understanding for the nature and origin of the systematic preference for alternating sequences, and against repeating ones.

Finally, the model by Griffiths and Tenenbaum (2001) produced a very bad fit to one of the sequences (\texttt{HTHTH}), which was judged by people to not be a very good random sequence, but the model ranked it highly.
It seems that people also have a bias against repeating the higher-order pattern events (e.g., two consecutive alternations in sequence \texttt{HTH}).
We were able to add this bias into the Bayesian model in Equation~\ref{eq:model-GT2001} with an additional additive term ($M_k$):
\begin{equation}\label{eq:model-augmented}
  P(R_k = \mathtt{H}) = \frac{1}{1+e^{-\lambda (L_k + M_k)}}
\end{equation}
where $M_k$ performs a similar function as $L_k$, except being based on the numbers of the second-order pattern events, $O_{\mathtt{H}}$ and $O_{\mathtt{T}}$ (either alternation or repetition depending the choice at $R_{k-1}$),
\begin{equation}\label{eq:log-likelihood-M}
  M_k = \log \left(\frac{O_{\mathtt{T}} + 1}{O_{\mathtt{H}} + 1} \right), \quad k \geq 3
\end{equation}
This augmented model now produces an excellent fit to the full set of sequence data points.
Again, the optimal value of the bias-gain parameter $\lambda$, which now applies to both sources of bias, remains the same $0.51$ value predicted by our neural model.



\section{Conclusion}
In conclusion, we find that the latent structure in simple probabilistic sequences shapes the learning dynamics in a neural model, producing a novel ``rational'' explanation for what has generally been considered a curious failure of human probabilistic understanding.
Our findings demonstrate that the waiting time statistics can be captured  implicitly by the learning mechanism of temporal integration, without instruction, through mere exposure to the input stimuli.
This supports the claim that the human mind might have evolved an accurate sense of randomness from the learning environment but may fail to reveal it by the criterion of a particular measuring device \cite{Pinker1997}.
For example, the alternation bias, as a result of averaging the mean time and waiting time statistics, would have been judged as ``irrational'' if it is measured against the mean time statistics alone.

In addition, our results highlight the connection between the temporally distributed predictive learning \cite{OReilly2012wiki,OReilly2014TI,Gerstner2012} and abstract structured representations \cite{Griffiths2001,Tenenbaum2011}.
The remarkable fit of the parameters derived from this neural model with a Bayesian model derived from very different considerations reinforces the idea that the temporal integration mechanisms in our neural model provide a good account of human information integration over time.
We have also recently shown how this same neural temporal integration and learning framework can account for human causal learning \cite{OReilly2014blicket}, in a way that is also compatible with existing Bayesian models of causal reasoning \cite{Griffiths2010TiCS}.
This ability to bridge between levels of analysis across multiple domains represents a rare and important development, with the potential to both ground these abstract models in underlying neural mechanisms, and provide a simpler explanatory understanding of the emergent behavior of these neural models.


\begin{acknowledgments}
This work was supported by the Office of Naval Research (ONR) grant number N00014-08-1-0042, and Intelligence Advanced Research Projects Activity (IARPA) via Department of the Interior (DOI) contract number D10PC20021. The US Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DOI, or the US Government.
\end{acknowledgments}

%%% abbreviation of journal titles: http://www.ncbi.nlm.nih.gov/nlmcatalog/journals
\begin{thebibliography}{10}
\bibitem{HuffD1959}
Huff D (1959) {\em How to take a chance} (Norton, New York).

\bibitem{Tversky1971}
Tversky A, Kahneman D (1971) Belief in the law of small numbers. {\em Psychol Bull} 76(2):105--110.

\bibitem{Tversky1974}
Tversky A, Kahneman D (1974) Judgment under uncertainty: Heuristics and biases. {\em Science} 185(4157):1124--1131.

\bibitem{Sun2010jdm}
Sun Y, Wang H (2010) Gambler's fallacy, hot hand belief, and time of patterns. {\em Judgm Decis Mak} 5(2):124--132.

\bibitem{Sun2010cogpsy}
Sun Y, Wang H (2010) Perception of randomness: On the time of streaks. {\em Cogn Psychol} 61(4):333--342.

\bibitem{OReilly2012wiki}
O'Reilly RC, Munakata Y, Frank MJ, Hazy TE, Contributors (2012) {\em
  Computational Cognitive Neuroscience} (Wiki Book, 1st Edition, URL:
  http://ccnbook.colorado.edu).

\bibitem{OReilly2014TI}
O'Reilly RC, Wyatte D, Rohrlich J (2014) Learning through time in the thalamocortical loops. {\em Preprint at: http://arxiv.org/abs/1407.3432\/}.

\bibitem{Griffiths2001}
Griffiths TL, Tenenbaum JB (2001) Randomness and coincidences: Reconciling intuition and probability theory. {\em Proceedings of the 23rd annual conference of the cognitive science society}, eds Moore JD, Stenning K (Lawrence Erlbaum, Mahwah, NJ), pp 398--403.

\bibitem{Falk1997}
Falk R, Konold C (1997) Making sense of randomness: Implicit encoding as a basis for judgment. {\em Psychol Rev} 104(2):301-318.

\bibitem{Nickerson2002}
Nickerson RS (2002) The production and perception of randomness. {\em Psychol Rev} 109(2):330--357.

\bibitem{Aslin2012}
Aslin RN, Newport EL (2012). Statistical learning: From acquiring specific items to forming general rules. {\em Curr Dir Psychol Sci} 21(3):170--176.

\bibitem{Pouget2013}
Pouget A, Beck JM, Ma WJ, Latham PE (2013) Probabilistic brains: Knowns and unknowns. {\em Nat Neurosci} 16(9):1170--1178.

\bibitem{Tenenbaum2011}
Tenenbaum JB, Kemp C, Griffiths TL, Goodman ND (2011) How to grow a mind: Statistics, structure, and abstraction. {\em Science} 331(6022):1279--1285.

\bibitem{Goodfellow1938}
Goodfellow LD (1938) A psychological interpretation of the results of the Zenith radio experiments in telepathy. {\em J Exp Psychol} 23(6):601--632.

\bibitem{Pinker1997}
Pinker S (1997) {\em How the mind works} (Norton, New York).

\bibitem{Gerstner2012}
Gerstner W, Sprekeler H, Deco G (2012) Theory and simulation in neuroscience. {\em Science} 338(6103):60--65.

\bibitem{OReilly2014blicket}
O'Reilly RC, {et al.}  (in preparation) Learning to infer causal structure over time.

\bibitem{Griffiths2010TiCS}
Griffiths TL, Chater N, Kemp C, Perfors A, Tenenbaum JB (2010) Probabilistic models of cognition: Exploring representations and inductive biases. {\em Trends Cogn Sci} 14(8):357--364.
\end{thebibliography}

\end{article}

\begin{figure}
  \centering\includegraphics[width=.5\textwidth]{RND-Figs/Figure1}
  \caption{Time of patterns described by the probability of alternation between consecutive trials ($p_A$).
  \textbf{A}. Transitions between patterns of length $2$.
  At $p_A\!=\!1/2$, the process has the same chance to visit either a repetition state (\texttt{HH} or \texttt{TT}) or an alternation state (\texttt{HT} or \texttt{TH}).
  However, it takes a minimum of $3$ transitions for the process to leave then revisit a repetition state (e.g., \texttt{HH} $\rightarrow$ \texttt{HT} $\rightarrow$ \texttt{TH} $\rightarrow$ \texttt{HH}), but only $2$ for an alternation state (e.g., \texttt{HT} $\rightarrow$ \texttt{TH} $\rightarrow$ \texttt{HT}).
  \textbf{B}. Equilibriums by $p_A$ values. A repetition ($R$) and an alternation ($A$) have the same mean time $E[T_R] = E[T_A]$ at $p_A\!=\!1/2$, the same waiting time $E[T^*_R] = E[T^*_A]$ at $p_A\!=\!1/3$, and the same sum $E[T_R] + E[T^*_R] = E[T_A] + E[T^*_A]$ at $p_A\!=\!3/7$.
  }
  \label{fig1}
\end{figure}


\begin{figure}
  \centering\includegraphics[width=.5\textwidth]{RND-Figs/Figure2}
  \caption{Neural model of temporal integration to capture the statistics of pattern times in random sequences.
  \textbf{A}. Architecture of the neural model.
  A single sensory input layer scans through a sequence of binary digits one digit at a time (input at $t-1$ is for illustration only).
  An internal prediction layer, with bidirectional connections from the input layer and its own temporal context representation, attempts to predict the next input.
  \textbf{B}. Neural model behavior depicted by the ratio between repetition and alternation detectors in response to the actual probability of alternation ($p_A$) in the input sequences.
  At $p_A = 1/2$, the model showed $R/A \approx 0.70$ (i.e., fewer repetition detectors than alternation detectors).
  Error bars ($\pm$SEM) represent the variability of model predictions. The dotted line is the squared total time ratio between alternation and repetition patterns (Equation~\ref{eq:time-ratio-squared}).
  }
  \label{fig2}
\end{figure}


\begin{figure*}
  \centering\includegraphics[width=.7\textwidth]{RND-Figs/Figure3}
  \caption{Bayesian models fitting to human data in random sequence production.
  \textbf{A}. Probabilities of the generated random sequences, collapsed over the first choice (e.g., \texttt{HHHHH} is combined with \texttt{TTTTT}).
  Human data represent the responses of $20,\!099$ participants \cite{Goodfellow1938}.
  In the model by Griffiths and Tenenbaum (2001) (Equation~\ref{eq:model-GT2001}), the bias-gain parameter $\lambda \approx 0.60$ was obtained by best-fitting the model to $15$ out of $16$ human data points (excluding ``\texttt{HTHTH}'').
  In our Augmented Model (Equation~\ref{eq:model-augmented}), $\lambda \approx 0.51$ was derived from the emergent behavior of the neural model.
  \textbf{B}. Best-fitting $\lambda$ values for the model by Griffiths and Tenenbaum (2001) and the Augmented Model, with either the selected or the full data set.
  In both data sets, the optimal $\lambda$ value for the augmented model remained the same at $0.51$ as predicted by the neural model.
  }
  \label{fig3}
\end{figure*}

\end{document}


